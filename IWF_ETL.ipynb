{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e4fee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import psycopg2 as ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec36ac97",
   "metadata": {},
   "source": [
    "# An Exercise in Creating an ETL (Extract, Transform, Load) Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0ab697",
   "metadata": {},
   "source": [
    "The International Weightlifting Federation (IWF) is the governing body for the sport of Olympic Weightlifting. They decide on and enforce the qualifications for Olympic qualification. They also put on international competitions in conjunction with the national governing body of Olympic Weightlifting in whatever country the competition is hosted in. \n",
    "\n",
    "I am taking data from the official IWF website (https://beta.iwf.sport/) and performing an exercise in creating an ETL pipeline. I will be using Python packages such as Tabula and bs4 to respectively read in pdf competition result books, and scrape the event results page of the IWF website to aggregate and organize international competition results.\n",
    "\n",
    "After aggregation, I will be using TabPy (a Tableau Python server) to build dashboards visualizing various statistics and insights that can be learned from these competition results. \n",
    "\n",
    "I am a fan of the sport and have been personally training and competing for about eight years now. I thought this would be an interesting project to work on in order to learn some industry standard technologies and methodologies that would look good on a résumé. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10099f8a",
   "metadata": {},
   "source": [
    "In the sport of Olympic Weightlifting, each athlete gets a total of six attempts in competition. Three [Snatch](https://www.youtube.com/watch?v=RqrBaArr1uI) (SN) attempts and three [Clean & Jerk](https://www.youtube.com/watch?v=kn73_fb_eOs) (CJ) attempts. The athlete's best successful lift in each discipline is added together to form their total. The athlete with the highest total in each weight class wins. \n",
    "\n",
    "The current weight classes are as follows:\n",
    "\n",
    "    Men:        Women:\n",
    "    55kg        45kg\n",
    "    61kg        49kg \n",
    "    67kg        55kg\n",
    "    73kg        59kg\n",
    "    81kg        64kg\n",
    "    89kg        71kg\n",
    "    96kg        76kg\n",
    "    102kg       81kg\n",
    "    109kg       87kg\n",
    "    +109kg      +87kg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310fcdb-8601-48ae-b06d-46e4517daf84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Collecting and Extracting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f4d5a8-34cb-4a05-9a76-231ced286b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    \"\"\"\n",
    "    Given a URL, uses BeautifulSoup to create `soup` object which\n",
    "    can be used for html scraping.\n",
    "\n",
    "    Args:\n",
    "        url (string) : url from IWF Results by Events page.\n",
    "        \n",
    "    Returns:\n",
    "        soup (BeautifulSoup) : BeautifulSoup object.\n",
    "    \"\"\"\n",
    "\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.text, \"html\")\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c36347-4fa5-4ae0-89d0-dc6771756f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(soup):\n",
    "    \"\"\"\n",
    "    Given `soup`, scrapes page html to obtain competition information.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup) : BeautifulSoup object.\n",
    "        \n",
    "    Returns:\n",
    "        comp_info (list) : List containing competition information on each\n",
    "                           athlete, gotten from provided url.\n",
    "    \"\"\"\n",
    "    \n",
    "    comp_info_dirty = []\n",
    "    grab_next = 0\n",
    "\n",
    "    # Grabbing athlete information from all 4 pages of an event\n",
    "    # (Men's Total, Women's Total, Men's Snatch/CJ, Women's Snatch/CJ)\n",
    "    \n",
    "    for line in soup.find_all(\"p\"):\n",
    "        if line.get_text().strip() == \"Total:\":\n",
    "            grab_next = 1\n",
    "        elif line.get_text().strip() == \"Rank:\":\n",
    "            grab_next = 0\n",
    "        elif grab_next == 1:\n",
    "            comp_info_dirty.append(line.get_text().strip())\n",
    "\n",
    "    # Removing labels from info list for easier entry into dfs\n",
    "\n",
    "    comp_info = []\n",
    "    # i, line in enumerate(comp_info_dirty)\n",
    "    for line in comp_info_dirty:\n",
    "        if \":\" in line:\n",
    "            line = line.split(\":\")[1].strip()\n",
    "        comp_info.append(line)\n",
    "    \n",
    "    return comp_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d370f192-821e-4459-b96a-1c3373743928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(soup):\n",
    "    \"\"\"\n",
    "    Given soup, extracts athlete names.\n",
    "\n",
    "    Args:\n",
    "        soup (BeatifulSoup) : BeatifulSoup object.\n",
    "\n",
    "    Returns:\n",
    "        names_men (list) : List containing the names of each male athlete.\n",
    "        names_women (list) : List contained the names of each female athlete.\n",
    "    \"\"\"\n",
    "\n",
    "    name_soup_men = soup.find(\"div\", {\"id\" : \"men_total\"})\n",
    "    html_split_men = name_soup_men.get_text().strip().split(\"\\n\")\n",
    "    elements_men = [i for i in html_split_men if i != \"\"]\n",
    "\n",
    "    name_soup_women = soup.find(\"div\", {\"id\" : \"women_total\"})\n",
    "    html_split_women = name_soup_women.get_text().strip().split(\"\\n\")\n",
    "    elements_women = [i for i in html_split_women if i != \"\"]\n",
    "    \n",
    "    names_men = []\n",
    "    name_next = 0\n",
    "    for i in elements_men:\n",
    "        if \"Rank: \" in i:\n",
    "            name_next = 1\n",
    "        elif \"kg Men\" in i:\n",
    "            names_men.append(i)\n",
    "        elif name_next == 1:\n",
    "            names_men.append(i)\n",
    "            name_next = 0\n",
    "\n",
    "    names_women = []\n",
    "    name_next = 0\n",
    "    for i in elements_women:\n",
    "        if \"Rank: \" in i:\n",
    "            name_next = 1\n",
    "        elif \"kg Women\" in i:\n",
    "            names_women.append(i)\n",
    "        elif name_next == 1:\n",
    "            names_women.append(i)\n",
    "            name_next = 0\n",
    "    \n",
    "    return names_men, names_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc27c73f-06ad-43e8-86a5-0a9d9a1a76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_athlete_numbers(soup, athlete_names_men, athlete_names_women):\n",
    "    \"\"\"\n",
    "    Given a list of all athletes in a competition, find the \n",
    "    number of athletes in each session for both males and females.\n",
    "\n",
    "    Args:\n",
    "        soup (BeatifulSoup) : BeautifulSoup object.\n",
    "        athlete_names_men (list) : List of male athlete names.\n",
    "        athlete_names_women (list) : List of female athlete names.\n",
    "\n",
    "    Returns:\n",
    "        athletes_per_class (dict) : Dictionary containing weight classes for \n",
    "                                    each gender and the number of athletes in that \n",
    "                                    class as key:value pairs.\n",
    "        total_male_athletes (int) : Number of male athletes in a given competition.\n",
    "        total_female_athletes (int) : Number of female athletes in a given competition.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary containing weight classes and the number of athletes\n",
    "    # in that weight class as key:value pairs. Male weight classes \n",
    "    # are listed first.\n",
    "    athletes_per_class = {}\n",
    "    \n",
    "    for class_ in soup.find_all(\"h3\"):\n",
    "        athletes_per_class[class_.get_text()] = 0\n",
    "\n",
    "    class_ = \"\"\n",
    "    for line in athlete_names_men:\n",
    "        if \"kg Men\" in line:\n",
    "            class_ = line\n",
    "        else:\n",
    "            athletes_per_class[class_] += 1\n",
    "\n",
    "\n",
    "    class_ = \"\"\n",
    "    for line in athlete_names_women:\n",
    "        if \"kg Women\" in line:\n",
    "            class_ = line\n",
    "        else:\n",
    "            athletes_per_class[class_] += 1\n",
    "\n",
    "    total_male_athletes = sum([athletes_per_class[class_] for class_ in athletes_per_class if \"Men\" in class_])\n",
    "    total_female_athletes = sum([athletes_per_class[class_] for class_ in athletes_per_class if \"Women\" in class_])\n",
    "    \n",
    "    return athletes_per_class, total_male_athletes, total_female_athletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c59734-1196-4cef-9963-72e3ec9b503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dfs(soup, total_male_athletes, total_female_athletes, athletes_per_class, comp_info, comp_id):\n",
    "    \"\"\"\n",
    "    Creates data frames of competition information for all male and female \n",
    "    weight classes.\n",
    "\n",
    "    Args:\n",
    "        soup (BeatifulSoup) : BeautifulSoup object.\n",
    "        total_male_athletes (int) : Number of male athletes in a given competition.\n",
    "        total_female_athletes (int) : Number of female athletes in a given competition.\n",
    "        athletes_per_class (dict) : Dictionary containing weight classes for \n",
    "                                    each gender and the number of athletes in that \n",
    "                                    class as key:value pairs.\n",
    "        comp_info (list) : List containing competition information on each athlete.\n",
    "        comp_id (int) : Unique competition ID as found in event page URL.\n",
    "\n",
    "     Returns :\n",
    "         results_dict_unmarked (dict) : Dictionary containing competition results for all male \n",
    "                                        and female weight classes. Missed attempts are not \n",
    "                                        indicated.\n",
    "    \"\"\"\n",
    "    results_dict_unmarked = {}\n",
    "\n",
    "    for class_ in soup.find_all(\"h3\"):\n",
    "        results_dict_unmarked[class_.get_text()] = ...\n",
    "\n",
    "\n",
    "    start_index = total_male_athletes * 9 + 1\n",
    "\n",
    "    men_dfs_created = 0\n",
    "    gender = \"M\"\n",
    "\n",
    "    for class_ in athletes_per_class:\n",
    "\n",
    "        # Result dfs for men have been created, move on to women\n",
    "        if \"Women\" in class_ and men_dfs_created == 0:\n",
    "            men_dfs_created = 1\n",
    "            start_index += total_female_athletes * 9 \n",
    "            gender = \"F\"\n",
    "        \n",
    "        stop_index_sn = start_index + athletes_per_class[class_]*10\n",
    "    \n",
    "        start_index_cj = stop_index_sn + 1\n",
    "        stop_index_cj = start_index_cj + athletes_per_class[class_]*10\n",
    "    \n",
    "        start_index_total = stop_index_cj + 1\n",
    "        stop_index_total = start_index_total + athletes_per_class[class_]*9\n",
    "\n",
    "        sn_d = {\n",
    "                \"comp_id\" : comp_id,\n",
    "                \"Name\" : comp_info[start_index + 1:stop_index_sn:10],\n",
    "                \"Gender\" : gender,\n",
    "                \"Nation\" : comp_info[start_index + 2:stop_index_sn:10],\n",
    "                \"Born\" : comp_info[start_index + 3:stop_index_sn:10],\n",
    "                \"Bodyweight\" : comp_info[start_index + 4:stop_index_sn:10], \n",
    "                \"Session\" : comp_info[start_index + 5:stop_index_sn:10],\n",
    "                \"SN 1\" : comp_info[start_index + 6:stop_index_sn:10],\n",
    "                \"SN 2\" : comp_info[start_index + 7:stop_index_sn:10], \n",
    "                \"SN 3\" : comp_info[start_index + 8:stop_index_sn:10],\n",
    "                \"Best SN\" : comp_info[start_index + 9:stop_index_sn:10],\n",
    "                # \"Total\" : comp_info[start_index_total + 8:stop_index_total:9] \n",
    "                }\n",
    "\n",
    "        cj_d = {\n",
    "                \"Name\" : comp_info[start_index_cj + 1:stop_index_cj:10],\n",
    "                \"CJ 1\" : comp_info[start_index_cj + 6:stop_index_cj:10],\n",
    "                \"CJ 2\" : comp_info[start_index_cj + 7:stop_index_cj:10],\n",
    "                \"CJ 3\" : comp_info[start_index_cj + 8:stop_index_cj:10],\n",
    "                \"Best CJ\" : comp_info[start_index_cj + 9:stop_index_cj:10]\n",
    "                }\n",
    "        \n",
    "        sn_df = pd.DataFrame(data=sn_d)\n",
    "        cj_df = pd.DataFrame(data=cj_d)\n",
    "        results_dict_unmarked[class_] = [sn_df, cj_df]\n",
    "        start_index = stop_index_total + 1\n",
    "\n",
    "    return results_dict_unmarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a014af-1085-41bb-a79f-24c58b09b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_missed_attempts(results_dict_unmarked, soup):\n",
    "    \"\"\"\n",
    "    Iterates through SN and CJ result data frames in results_dict\n",
    "    and marks missed attempts.\n",
    "\n",
    "    Args: \n",
    "        results_dict_unmarked (dict) : Dictionary containing competition results for all male \n",
    "                                       and female weight classes. Missed attempts are not \n",
    "                                       indicated.\n",
    "        soup (BeautifulSoup) : BeautifulSoup object.\n",
    "\n",
    "    Returns:\n",
    "        results_dict (dict) : Dictionary of competition results with missed attempts indicated. \n",
    "    \"\"\"\n",
    "\n",
    "    # Reading in male and female athletes' results in html \n",
    "    html_snatchjerk_men = soup.find(\"div\", {\"id\" : \"men_snatchjerk\"})\n",
    "    html_snatchjerk_women = soup.find(\"div\", {\"id\" : \"women_snatchjerk\"})\n",
    "    \n",
    "    # Using regular expressions to extract missed attempts from html strings\n",
    "    # Matching all instances of 1 or more digit (0-9)\n",
    "    missed_attempts_pattern = re.compile(r'\\d+|(\\-{3})')\n",
    "    \n",
    "    # Applying missed_attempts_pattern\n",
    "    html_tags_men = html_snatchjerk_men.find_all('strong', text=missed_attempts_pattern)\n",
    "    html_tags_women = html_snatchjerk_women.find_all('strong', text=missed_attempts_pattern)\n",
    "\n",
    "    # First (total_male_athletes * 3) indices of html_tags contain total results information\n",
    "    start_index = 0 \n",
    "\n",
    "    men_marked = 0\n",
    "\n",
    "    for class_ in results_dict_unmarked:\n",
    "        \n",
    "        for index, df in enumerate(results_dict_unmarked[class_]):\n",
    "\n",
    "            if \"Women\" in class_ and men_marked == 0:\n",
    "                men_marked = 1\n",
    "                start_index = 0\n",
    "    \n",
    "            stop_index = start_index + len(df) * 3\n",
    "    \n",
    "            if men_marked == 0:\n",
    "                results = html_tags_men[start_index:stop_index]\n",
    "                \n",
    "            elif men_marked == 1:\n",
    "                results = html_tags_women[start_index:stop_index]\n",
    "\n",
    "            # Setting iterators to slice results list, updated after each athlete's 3 SN/CJ attempts\n",
    "            # have been marked\n",
    "            j = 0\n",
    "            k = j + 3\n",
    "            for athlete in df.index:\n",
    "\n",
    "                # Marking SN attempts\n",
    "                if index == 0:\n",
    "                    \n",
    "                    # Setting i = 1 to begin with 1st attempt in the SN\n",
    "                    i = 1\n",
    "                    \n",
    "                    for attempt in results[j:k]:\n",
    "                        if \"<strike>\" in str(attempt):\n",
    "                            df.loc[athlete, 'SN' + ' ' + str(i)] = f'{df.loc[athlete, \"SN\" + \" \" + str(i)]}' + ' ' + 'x' \n",
    "                        elif \"---\" in str(attempt):\n",
    "                            pass\n",
    "                        \n",
    "                        i += 1\n",
    "                    \n",
    "                # Marking CJ attempts\n",
    "                elif index == 1:\n",
    "                    i = 1\n",
    "                    for attempt in results[j:k]:\n",
    "                        if \"<strike>\" in str(attempt):\n",
    "                            df.loc[athlete, 'CJ' + ' ' + str(i)] = f'{df.loc[athlete, \"CJ\" + \" \" + str(i)]}' + ' ' + 'x' \n",
    "                        elif \"---\" in str(attempt):\n",
    "                            pass\n",
    "    \n",
    "                        i += 1\n",
    "\n",
    "                # Moving to the next three attempts to be marked\n",
    "                j = k\n",
    "                k += 3\n",
    "\n",
    "            # Updating \n",
    "            if index == 0:\n",
    "                start_index = stop_index \n",
    "            elif index == 1:\n",
    "                start_index = stop_index + len(df) * 2\n",
    "\n",
    "    results_dict_marked = results_dict_unmarked\n",
    "\n",
    "    return results_dict_marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3efbcca-2eaa-4751-8ec1-3b3124b6a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(results_dict_marked):\n",
    "    \"\"\"\n",
    "    Iterates through each weightclass in results_dict and merges\n",
    "    SN/CJ result dataframes by athlete name. Result will be a singular\n",
    "    dataframe for each weight class containing SN and CJ result information.\n",
    "\n",
    "    Args:\n",
    "        results_dict_marked (dict): Dictionary of competition results with missed attempts indicated. \n",
    "                                    SN/CJ results are contained at index 0/1 respectively.\n",
    "\n",
    "    Returns: \n",
    "        results_dict_grouped (dict) : Dictionary of competition results. SN/CJ results displayed in a single\n",
    "                                      dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    results_dict_grouped = {}\n",
    "    for class_ in results_dict_marked:\n",
    "        sn_results = results_dict_marked[class_][0]\n",
    "        cj_results = results_dict_marked[class_][1]\n",
    "        results_dict_grouped[class_] = pd.merge(sn_results, cj_results, how=\"outer\", on=\"Name\")\n",
    "\n",
    "        # Moving \"Total\" column to the right of df\n",
    "        # total_col = results_dict_grouped[class_].pop(\"Total\")\n",
    "        # results_dict_grouped[class_].insert(13, \"Total\", total_col)\n",
    "        \n",
    "    return results_dict_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ae9a5b-dcb2-4208-897f-14ce0b1a3e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_data_pipeline(url, comp_id):\n",
    "    \"\"\"\n",
    "    Calls all previously defined loading/cleaning functions.\n",
    "\n",
    "    Args:\n",
    "        url (str) : url from IWF Results by Events page.\n",
    "\n",
    "    Returns:\n",
    "        results_dict (dict) : Dictionary of competition results.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Creating BeautifulSoup object for html scraping.\n",
    "    soup = get_soup(url)\n",
    "\n",
    "    # Extracting relevant competition information.\n",
    "    comp_info = get_info(soup)\n",
    "\n",
    "    # Extracting athlete names from comp_info list.\n",
    "    athlete_names_men, athlete_names_women = get_names(soup)\n",
    "\n",
    "    # Calculating relevant athlete number for data frame construction.\n",
    "    athletes_per_class, total_male_athletes, total_female_athletes = get_athlete_numbers(soup, athlete_names_men, athlete_names_women)\n",
    "\n",
    "    # Creating unmarked dictionary of competition results.\n",
    "    results_dict_unmarked = make_dfs(soup, total_male_athletes, total_female_athletes, \n",
    "                                     athletes_per_class, comp_info, comp_id)\n",
    "\n",
    "    # Marking missed attempts in results dictionary.\n",
    "    results_dict_marked = mark_missed_attempts(results_dict_unmarked, soup)\n",
    "\n",
    "    # Merge SN/CJ result dfs into a single df.\n",
    "    results_dict = merge_dfs(results_dict_marked)\n",
    "\n",
    "    return results_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642fca5d-f37e-46f0-9a9f-7f4f03107355",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Competition Logistic Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f124a6-dbd5-47d6-b54b-57e209921945",
   "metadata": {},
   "source": [
    "I would like to also hold competition information such as the competition type, the location, and the date of the competition. To find this information, more html scraping of the IWF Results by Events page is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f1038fd-a71b-42b2-bb9e-3775c78f5583",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_page_soup = get_soup(\"https://iwf.sport/results/results-by-events/?event_type=all&event_age=all&event_nation=all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "057d570d-bc6b-4551-ad7f-99a76ae58060",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_page_url = \"https://iwf.sport/results/results-by-events/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25553e45-4a7d-4eb0-b27e-5bf10596b6db",
   "metadata": {},
   "source": [
    "The previously defined data pipeline which gets competition results information into a pandas dataframe for each weight class requires a url as input. The url for each specific event page is found within <a> tags on the IWF Results by Events page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b166ce25-9a0c-43fe-b082-d2dc21fc70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_comp_logistics_df(url):\n",
    "    \"\"\"\n",
    "    Given the IWF Results by Events url, creates a pandas dataframe containing\n",
    "    the type, location, and date of each competition on the page.\n",
    "\n",
    "    Args:\n",
    "        url (str) : IWF Results by Events url.\n",
    "    Returns:\n",
    "        logisitcs_df (pandas data frame): Data frame containing compeition logistic information.\n",
    "    \"\"\"\n",
    "\n",
    "    # Defining Results by Events Page BeatifulSoup object\n",
    "    events_page_soup = get_soup(url)\n",
    "\n",
    "    comp_id = []\n",
    "    comp_names = []\n",
    "    comp_locations = []\n",
    "    comp_dates = []\n",
    "\n",
    "    # Each competition has a unique ID, grabbing that here\n",
    "    for line in events_page_soup.find_all(\"a\", {\"class\" : \"card\"}):\n",
    "        id = line.get('href').split(\"=\")[1]\n",
    "        comp_id.append(int(id))\n",
    "\n",
    "    # On the Results by Events page, each competition title is contained within the class below\n",
    "    for name in events_page_soup.find_all(\"div\", {\"class\" : \"col-md-5 col-12 not__cell__767__full\"}):\n",
    "        comp_names.append(name.get_text().strip())\n",
    "\n",
    "    # The location of each competition is contained within the class below \n",
    "    for location in events_page_soup.find_all(\"div\", {\"class\" : \"col-md-3 col-4 not__cell__767\"}): \n",
    "        comp_locations.append(location.get_text().strip())\n",
    "\n",
    "    # The date of each compeition is contained within the class below\n",
    "    for date in events_page_soup.find_all(\"div\", {\"class\" : \"col-md-2 col-4 not__cell__767\"}): \n",
    "        comp_dates.append(date.get_text().strip())\n",
    "\n",
    "    d = {\n",
    "        \"comp_id\" : comp_id,\n",
    "        \"comp_name\" : comp_names,\n",
    "        \"comp_location\" : comp_locations,\n",
    "        \"comp_date\" : comp_dates\n",
    "        }\n",
    "\n",
    "    logistics_df = pd.DataFrame(data=d)\n",
    "\n",
    "    return logistics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc3eccc-f8c5-45c2-88ec-2c3e1aa29e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_logistics_df = make_comp_logistics_df(\"https://iwf.sport/results/results-by-events/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f1d89b4-9349-4b9b-90ee-f4bfbbff6204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_id</th>\n",
       "      <th>comp_name</th>\n",
       "      <th>comp_location</th>\n",
       "      <th>comp_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>596</td>\n",
       "      <td>Pan-American Championships</td>\n",
       "      <td>Caracas, VEN</td>\n",
       "      <td>Feb 24, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>595</td>\n",
       "      <td>Oceania Championships</td>\n",
       "      <td>Auckland, AUS</td>\n",
       "      <td>Feb 21, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>594</td>\n",
       "      <td>European Championships</td>\n",
       "      <td>Sofia, BUL</td>\n",
       "      <td>Feb 12, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>African Championships</td>\n",
       "      <td>Ismailia, EGY</td>\n",
       "      <td>Feb 05, 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592</td>\n",
       "      <td>Asian Championships</td>\n",
       "      <td>Tashkent, UZB</td>\n",
       "      <td>Feb 03, 2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comp_id                   comp_name  comp_location     comp_date\n",
       "0      596  Pan-American Championships   Caracas, VEN  Feb 24, 2024\n",
       "1      595       Oceania Championships  Auckland, AUS  Feb 21, 2024\n",
       "2      594      European Championships     Sofia, BUL  Feb 12, 2024\n",
       "3      593       African Championships  Ismailia, EGY  Feb 05, 2024\n",
       "4      592         Asian Championships  Tashkent, UZB  Feb 03, 2024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_logistics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdc1e82-0f6d-436b-8b3f-d51d86ea2de8",
   "metadata": {},
   "source": [
    "# Connecting to PostgreSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e929b058-38b1-478d-9c1f-b5e520b3095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = \"localhost\"\n",
    "database = \"iwfetl\"\n",
    "username = \"connersparks\"\n",
    "port_id = 5432\n",
    "\n",
    "conn = None\n",
    "cur = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3483abd3-0712-4452-ae10-8f3ccc16c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db(hostname, database, username, port_id):\n",
    "    \"\"\"\n",
    "    Connects to PostgreSQL database.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        conn = ps.connect(\n",
    "            host=hostname, \n",
    "            dbname=database, \n",
    "            user=username, \n",
    "            port=port_id)\n",
    "    \n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "    \n",
    "    else:\n",
    "        print(\"Connected!\")\n",
    "\n",
    "    return conn\n",
    "\n",
    "# finally:\n",
    "#     if cur is not None:\n",
    "#         cur.close()\n",
    "#     if conn is not None:    \n",
    "#         conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29a7be44-4fe3-4873-ad46-35dd618511f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "conn = connect_to_db(hostname, database, username, port_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec6c867b-ae14-4858-8f4e-8c19db0499a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08a010-a02f-4cde-b8a7-6f053dbd2ce1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Loading Competition Logistics Table Into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a480f20c-e88a-4e3d-aceb-de9ec9987126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comp_logistics_table(curr):\n",
    "    \"\"\"\n",
    "    Given a cursor object, runs SQL create table command to create\n",
    "    a table containing competition logistics information.\n",
    "\n",
    "    Args:\n",
    "        curr (Psycopg2 Cursor) : Cursor object.\n",
    "    \"\"\"\n",
    "    create_competition_table_command = ( \"\"\" CREATE TABLE IF NOT EXISTS comp_logistics (\n",
    "                                        comp_id INTEGER PRIMARY KEY,\n",
    "                                        comp_name TEXT NOT NULL,\n",
    "                                        comp_location TEXT NOT NULL,\n",
    "                                        comp_date DATE NOT NULL\n",
    "                                        )\"\"\")\n",
    "\n",
    "    curr.execute(create_competition_table_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4abc7c28-ceb1-4395-87c0-3e1ef48a0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_comp_logistics_exists(curr, comp_id):\n",
    "    \"\"\"\n",
    "    Checks if given comp_id exists in the comp_logistics table.\n",
    "\n",
    "    Args:\n",
    "        curr (Psycopg2 Cursor) : Cursor object.\n",
    "        comp_id (int) : Competition's unique key.\n",
    "\n",
    "    Returns: True if competition is found, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # %s enables a parameter to be passed into SQL query, comp_id in this case\n",
    "    query = (\"\"\"SELECT comp_id FROM comp_logistics WHERE comp_id = %s\"\"\") \n",
    "\n",
    "    curr.execute(query, (comp_id,))\n",
    "\n",
    "    return curr.fetchone() is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34464932-3d67-48ab-8e05-8d4683561f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_comp_logistics_table(curr, df):\n",
    "    tmp_df = pd.DataFrame(columns=[\"comp_id\", \"comp_name\", \"comp_location\", \"comp_date\"])\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        # If competition already exists within our table, do nothing\n",
    "        if check_comp_logistics_exists(curr, row[\"comp_id\"]):\n",
    "            continue\n",
    "        # If competition does not exists within our table, append it to a temporary df\n",
    "        else:\n",
    "            tmp_df.loc[len(tmp_df.index)] = row\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8bc90c3-5698-44b8-94ed-d08b7953908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_comp_logistics(curr, comp_id, comp_name, comp_location, comp_date):\n",
    "    \n",
    "    insert_command = (\"\"\"INSERT INTO comp_logistics (comp_id, comp_name, comp_location, comp_date)\n",
    "                    VALUES(%s, %s, %s, %s);\"\"\")\n",
    "\n",
    "    row_to_insert = (comp_id, comp_name, comp_location, comp_date)\n",
    "\n",
    "    curr.execute(insert_command, row_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ebb3d17-b676-4efc-9405-0a8d4dd47515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_from_comp_logistics_df_to_db(curr, df):\n",
    "    for i, row in df.iterrows():\n",
    "        insert_comp_logistics(curr, row[\"comp_id\"], row[\"comp_name\"], row[\"comp_location\"], row[\"comp_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af7e30de-852d-4008-9ea0-b4b39127dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_logistics_wrapper(curr, comp_logistics_df):\n",
    "    \"\"\"\n",
    "    Calls all functions to create and insert into comp_logistics table.\n",
    "\n",
    "    Args:\n",
    "        curr (psycopg2 Cursor) : psycopg2 cursor object.\n",
    "        comp_logistics_df (pandas df) : Dataframe of competition logistics from IWF\n",
    "                                        Results by Events page.\n",
    "    \"\"\"\n",
    "\n",
    "    create_comp_logistics_table(curr)\n",
    "\n",
    "    new_comp_logistics_df = update_comp_logistics_table(curr, comp_logistics_df)\n",
    "\n",
    "    append_from_comp_logistics_df_to_db(curr, new_comp_logistics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554d60f4-2d4f-4ce4-92da-f1332c383b55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Loading Competition Data Table Into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6331b251-3730-4207-b961-770fb47ef88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comp_data_table(curr):\n",
    "    \"\"\"\n",
    "    Given a cursor object, runs SQL create table command to create\n",
    "    a table containing competition logistics information.\n",
    "\n",
    "    Args:\n",
    "        curr (psycopg2 Cursor) : Cursor object.\n",
    "    \"\"\"\n",
    "\n",
    "    create_competition_data_table_command = (\"\"\" CREATE TABLE IF NOT EXISTS comp_data (\n",
    "                                            comp_id INTEGER NOT NULL,\n",
    "                                            Name TEXT NOT NULL,\n",
    "                                            Gender CHAR(1) NOT NULL,\n",
    "                                            Nation TEXT NOT NULL,\n",
    "                                            Born DATE NOT NULL,\n",
    "                                            Bodyweight FLOAT NOT NULL,\n",
    "                                            Session CHAR(1) NOT NULL,\n",
    "                                            sn_1 VARCHAR(10) NOT NULL,\n",
    "                                            sn_2 VARCHAR(10) NOT NULL,\n",
    "                                            sn_3 VARCHAR(10) NOT NULL,\n",
    "                                            best_sn VARCHAR(10) NOT NULL,\n",
    "                                            cj_1 VARCHAR(10) NOT NULL,\n",
    "                                            cj_2 VARCHAR(10) NOT NULL,\n",
    "                                            cj_3 VARCHAR(10) NOT NULL,\n",
    "                                            best_cj VARCHAR(10) NOT NULL\n",
    "                                            )\"\"\")\n",
    "\n",
    "    curr.execute(create_competition_data_table_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "200b7772-9991-4e4c-a76f-5a7bf991d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_comp_data_exists(curr, comp_id, name, nation, bweight, sn_1, sn_2, sn_3, best_sn, cj_1, cj_2, cj_3, best_cj):\n",
    "    \"\"\"\n",
    "    Checks if given comp_id exists in the comp_logistics table.\n",
    "\n",
    "    Args:\n",
    "        curr (psycopg2 Cursor) : Cursor object.\n",
    "        comp_id (int) : Competition's unique key.\n",
    "\n",
    "    Returns: True if competition is found, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # %s enables a parameter to be passed into SQL query, comp_id in this case\n",
    "    query = (\"\"\"SELECT comp_id FROM comp_data \n",
    "                WHERE comp_id = %s AND Name = %s AND Nation = %s AND Bodyweight = %s \n",
    "                AND sn_1 = %s AND sn_2 = %s AND sn_3 = %s AND best_sn = %s\n",
    "                AND cj_1 = %s AND cj_2 = %s AND cj_3 = %s AND best_cj = %s\"\"\") \n",
    "\n",
    "    vars = (comp_id, name, nation, bweight, sn_1, sn_2, sn_3, best_sn, cj_1, cj_2, cj_3, best_cj)\n",
    "\n",
    "    curr.execute(query, vars)\n",
    "\n",
    "    return curr.fetchone() is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8b73e0d-3dad-458d-bdbf-a2aff58e8dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_comp_data_table(curr, df):\n",
    "\n",
    "    tmp_df = pd.DataFrame(columns=[\"comp_id\",\n",
    "                                   \"Name\",\n",
    "                                   \"Gender\",\n",
    "                                   \"Nation\",\n",
    "                                   \"Born\",\n",
    "                                   \"Bodyweight\",\n",
    "                                   \"Session\",\n",
    "                                   \"SN 1\",\n",
    "                                   \"SN 2\",\n",
    "                                   \"SN 3\",\n",
    "                                   \"Best SN\",\n",
    "                                   \"CJ 1\",\n",
    "                                   \"CJ 2\",\n",
    "                                   \"CJ 3\",\n",
    "                                   \"Best CJ\",\n",
    "                                   \"Total\"\n",
    "                                  ])\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        # If competition already exists within our table, do nothing\n",
    "        if check_comp_data_exists(curr, row[\"comp_id\"], row[\"Name\"], row[\"Nation\"], row[\"Bodyweight\"], row[\"SN 1\"], row[\"SN 2\"], row[\"SN 3\"], row[\"Best SN\"], row[\"CJ 1\"], row[\"CJ 2\"], row[\"CJ 3\"], row[\"Best CJ\"]):\n",
    "            continue\n",
    "        else:\n",
    "            tmp_df.loc[len(tmp_df.index)] = row\n",
    "\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13c00d14-a0c1-4ddc-9cb9-05b2e0aa17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_comp_data(curr, comp_id, name, gender, nation, born, bodyweight, session, sn_1, sn_2, sn_3, best_sn, cj_1, cj_2, cj_3, best_cj):\n",
    "    \n",
    "    insert_command = (\"\"\"INSERT INTO comp_data (comp_id, name, gender, nation, born, bodyweight, session, \n",
    "                                                sn_1, sn_2, sn_3, best_sn, \n",
    "                                                cj_1, cj_2, cj_3, best_cj)              \n",
    "                        VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\"\"\")\n",
    "\n",
    "    row_to_insert = (comp_id, name, gender, nation, born, bodyweight, session, sn_1, sn_2, sn_3, best_sn, cj_1, cj_2, cj_3, best_cj)\n",
    "\n",
    "    curr.execute(insert_command, row_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73b65db2-b8bb-4cc7-9a7b-c066c8faa98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_from_comp_data_df_to_db(curr, df):\n",
    "    for i, row in df.iterrows():\n",
    "        insert_comp_data(curr, row[\"comp_id\"], row[\"Name\"], row[\"Gender\"], row[\"Nation\"], \n",
    "                         row[\"Born\"], row[\"Bodyweight\"], row[\"Session\"],\n",
    "                         row[\"SN 1\"], row[\"SN 2\"], row[\"SN 3\"], row[\"Best SN\"],\n",
    "                         row[\"CJ 1\"], row[\"CJ 2\"], row[\"CJ 3\"], row[\"Best CJ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4de33d5-7da4-44e0-b075-dafc9b362b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_data_wrapper(curr, results_dict):\n",
    "    \"\"\"\n",
    "    Calls all functions to create and insert into comp_data table.\n",
    "\n",
    "    Args:\n",
    "        curr (psycopg2 Cursor) : psycopg2 cursor object.\n",
    "        results_dict (dict) : Dictionary of results from a single competition.\n",
    "    \"\"\"\n",
    "\n",
    "    create_comp_data_table(curr)\n",
    "\n",
    "    # Iterating through each weight class and loading each into comp_data table\n",
    "    for class_ in results_dict:\n",
    "        new_comp_data_table = update_comp_data_table(curr, results_dict[class_])\n",
    "\n",
    "        append_from_comp_data_df_to_db(curr, new_comp_data_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00bbed-4201-4228-85e2-613a8dc0423b",
   "metadata": {},
   "source": [
    "# Updating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc2fb4e6-95ea-4c38-a42c-74fc73ef5ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    \"\"\"\n",
    "    Iterates through each competition on the IWF Results by Events page and \n",
    "    calls all previously defined cleaning/loading functions.\n",
    "    \"\"\"\n",
    "\n",
    "    events_page_url = \"https://iwf.sport/results/results-by-events/\"\n",
    "    events_page_soup = get_soup(events_page_url)\n",
    "    \n",
    "    # Connecting to iwf_etl database and creating cursor\n",
    "    conn = connect_to_db(hostname, database, username, port_id)\n",
    "    curr = conn.cursor()\n",
    "\n",
    "    # Creating competition logistics df\n",
    "    comp_logistitcs_df = make_comp_logistics_df(events_page_url)\n",
    "\n",
    "    # Creating and populating comp_logistics table\n",
    "    comp_logistics_wrapper(curr, comp_logistitcs_df)\n",
    "    \n",
    "    # Iterating through each competition on IWF Results by Events page,\n",
    "    # passing through pipeline, and loading into comp_data table\n",
    "    for comp in events_page_soup.find_all(\"a\", {\"class\" : \"card\"}):\n",
    "        comp_id_str = comp.get('href')\n",
    "        comp_link = events_page_url + comp_id_str\n",
    "\n",
    "        # Grabbing comp_id and casting to int\n",
    "        comp_id_int = int(comp.get('href').split('=')[1])\n",
    "\n",
    "        # Calling pipeline on each competition\n",
    "        results_dict = comp_data_pipeline(comp_link, comp_id_int)\n",
    "        print(f\"Results for competition {comp_id_int} aggregated.\")\n",
    "\n",
    "        try:\n",
    "            comp_data_wrapper(curr, results_dict)\n",
    "            print(f\"Competition {comp_id_int} loaded! \\n\")\n",
    "        except Exception as error:\n",
    "            print(f\"Competition {comp_id_int} failed to load. Halting pipeline.\")\n",
    "            print(error)\n",
    "            break\n",
    "    \n",
    "    conn.commit()\n",
    "    print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "67a4700b-6186-4b81-82ad-d6bea9a661bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n",
      "Results for competition 596 aggregated.\n",
      "Competition 596 loaded! \n",
      "Results for competition 595 aggregated.\n",
      "Competition 595 loaded! \n",
      "Results for competition 594 aggregated.\n",
      "Competition 594 loaded! \n",
      "Results for competition 593 aggregated.\n",
      "Competition 593 loaded! \n",
      "Results for competition 592 aggregated.\n",
      "Competition 592 loaded! \n",
      "Results for competition 587 aggregated.\n",
      "Competition 587 loaded! \n",
      "Results for competition 586 aggregated.\n",
      "Competition 586 loaded! \n",
      "Results for competition 581 aggregated.\n",
      "Competition 581 loaded! \n",
      "Results for competition 589 aggregated.\n",
      "Competition 589 loaded! \n",
      "Results for competition 588 aggregated.\n",
      "Competition 588 loaded! \n",
      "Results for competition 590 aggregated.\n",
      "Competition 590 loaded! \n",
      "Results for competition 584 aggregated.\n",
      "Competition 584 loaded! \n",
      "Results for competition 583 aggregated.\n",
      "Competition 583 loaded! \n",
      "Results for competition 582 aggregated.\n",
      "Competition 582 loaded! \n",
      "Results for competition 577 aggregated.\n",
      "Competition 577 loaded! \n",
      "Results for competition 580 aggregated.\n",
      "Competition 580 loaded! \n",
      "Results for competition 575 aggregated.\n",
      "Competition 575 loaded! \n",
      "Results for competition 576 aggregated.\n",
      "Competition 576 loaded! \n",
      "Results for competition 579 aggregated.\n",
      "Competition 579 loaded! \n",
      "Results for competition 578 aggregated.\n",
      "Competition 578 loaded! \n",
      "Results for competition 574 aggregated.\n",
      "Competition 574 loaded! \n",
      "Results for competition 591 aggregated.\n",
      "Competition 591 loaded! \n",
      "Results for competition 571 aggregated.\n",
      "Competition 571 loaded! \n",
      "Results for competition 572 aggregated.\n",
      "Competition 572 loaded! \n",
      "Results for competition 570 aggregated.\n",
      "Competition 570 loaded! \n",
      "Results for competition 569 aggregated.\n",
      "Competition 569 loaded! \n",
      "Results for competition 568 aggregated.\n",
      "Competition 568 loaded! \n",
      "Results for competition 567 aggregated.\n",
      "Competition 567 loaded! \n",
      "Results for competition 562 aggregated.\n",
      "Competition 562 loaded! \n",
      "Results for competition 544 aggregated.\n",
      "Competition 544 loaded! \n",
      "Results for competition 560 aggregated.\n",
      "Competition 560 loaded! \n",
      "Results for competition 563 aggregated.\n",
      "Competition 563 loaded! \n",
      "Results for competition 558 aggregated.\n",
      "Competition 558 loaded! \n",
      "Results for competition 561 aggregated.\n",
      "Competition 561 loaded! \n",
      "Results for competition 565 aggregated.\n",
      "Competition 565 loaded! \n",
      "Results for competition 557 aggregated.\n",
      "Competition 557 loaded! \n",
      "Results for competition 556 aggregated.\n",
      "Competition 556 loaded! \n",
      "Results for competition 555 aggregated.\n",
      "Competition 555 loaded! \n",
      "Results for competition 554 aggregated.\n",
      "Competition 554 loaded! \n",
      "Results for competition 545 aggregated.\n",
      "Competition 545 loaded! \n",
      "Results for competition 553 aggregated.\n",
      "Competition 553 loaded! \n",
      "Results for competition 552 aggregated.\n",
      "Competition 552 loaded! \n",
      "Results for competition 551 aggregated.\n",
      "Competition 551 loaded! \n",
      "Results for competition 550 aggregated.\n",
      "Competition 550 loaded! \n",
      "Results for competition 564 aggregated.\n",
      "Competition 564 loaded! \n",
      "Results for competition 549 aggregated.\n",
      "Competition 549 loaded! \n",
      "Results for competition 548 aggregated.\n",
      "Competition 548 loaded! \n",
      "Results for competition 547 aggregated.\n",
      "Competition 547 loaded! \n",
      "Results for competition 546 aggregated.\n",
      "Competition 546 loaded! \n",
      "Results for competition 530 aggregated.\n",
      "Competition 530 loaded! \n",
      "Results for competition 532 aggregated.\n",
      "Competition 532 loaded! \n",
      "Results for competition 543 aggregated.\n",
      "Competition 543 loaded! \n",
      "Results for competition 566 aggregated.\n",
      "Competition 566 loaded! \n",
      "Results for competition 542 aggregated.\n",
      "Competition 542 loaded! \n",
      "Results for competition 541 aggregated.\n",
      "Competition 541 loaded! \n",
      "Results for competition 529 aggregated.\n",
      "Competition 529 loaded! \n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
